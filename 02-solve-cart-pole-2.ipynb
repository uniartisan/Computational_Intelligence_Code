{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络控制倒立摆\n",
    "使用PSO算法控制训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "import random\n",
    "import numpy\n",
    "import math\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "import cart_pole\n",
    "import elitism\n",
    "import time\n",
    "\n",
    "# 粒子群算法\n",
    "from sko.PSO import PSO\n",
    "from sko.tools import set_run_mode\n",
    "\n",
    "# draw opt image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# PSO Algorithm constants:\n",
    "pop = 5200\n",
    "max_iter = 30\n",
    "w = 0.95\n",
    "c1 = 0.5\n",
    "c2 = 0.5\n",
    "\n",
    "# set the random seed:\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "# create the cart pole task class:\n",
    "cartPole = cart_pole.CartPole(RANDOM_SEED)\n",
    "NUM_OF_PARAMS = len(cartPole)\n",
    "# boundaries for layer size parameters:\n",
    "\n",
    "# weight and bias values are bound between -1 and 1:\n",
    "BOUNDS_LOW, BOUNDS_HIGH = -1.0, 1.0  # boundaries for all dimensions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitness calculation using the CrtPole class:\n",
    "# @jit\n",
    "def score(individual):\n",
    "    # RANDOM_SEED = random.randint(1,10000)\n",
    "    # cartPole1 = cart_pole.CartPole(RANDOM_SEED)\n",
    "    cartPole1 = cart_pole.CartPole()\n",
    "    # train 使用距离信息\n",
    "    return -1 * cartPole1.getTrainScore(individual),\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:99: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getTrainScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (110)\n",
      "\n",
      "File \"cart_pole.py\", line 110:\n",
      "    def getTrainScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getTrainScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 100:\n",
      "    @jit\n",
      "    def getTrainScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    }
   ],
   "source": [
    "# Genetic Algorithm flow:\n",
    "mode = 'multiprocessing'\n",
    "set_run_mode(score, mode)\n",
    "pso = PSO(func=score, n_dim=NUM_OF_PARAMS, pop=pop, max_iter=max_iter,\n",
    "          lb=BOUNDS_LOW, ub=BOUNDS_HIGH, w=w, c1=c1, c2=c2)\n",
    "\n",
    "tt = time.time()\n",
    "pso.run()\n",
    "tt2 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Solution =  [-0.22910466  1.          1.         -1.         -1.         -1.\n",
      "  1.         -1.         -1.          1.         -1.         -1.\n",
      "  1.          1.          1.         -1.         -1.          1.\n",
      " -0.53073991 -1.          1.          1.         -1.          1.\n",
      "  1.        ]\n",
      "Best Fitness =  [-498.32103402]\n",
      "Time used: 165.9038302898407 sec\n"
     ]
    }
   ],
   "source": [
    "# print best solution found:\n",
    "best = pso.gbest_x\n",
    "print()\n",
    "print(\"Best Solution = \", best)\n",
    "print(\"Best Fitness = \", pso.gbest_y)\n",
    "print('Time used: {} sec'.format(tt2-tt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.03963102  0.24230015  0.0266861  -0.25572422]\n",
      "reward =  1.0\n",
      "totalReward =  1.0\n",
      "done =  False\n",
      "\n",
      "2 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.03478502  0.04680755  0.02157161  0.04525506]\n",
      "reward =  1.0\n",
      "totalReward =  2.0\n",
      "done =  False\n",
      "\n",
      "3 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.03384887  0.24161364  0.02247672 -0.24054453]\n",
      "reward =  1.0\n",
      "totalReward =  3.0\n",
      "done =  False\n",
      "\n",
      "4 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.02901659  0.04617794  0.01766583  0.05914257]\n",
      "reward =  1.0\n",
      "totalReward =  4.0\n",
      "done =  False\n",
      "\n",
      "5 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.02809303  0.2410422   0.01884868 -0.22791472]\n",
      "reward =  1.0\n",
      "totalReward =  5.0\n",
      "done =  False\n",
      "\n",
      "6 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.02327219  0.43588978  0.01429038 -0.514593  ]\n",
      "reward =  1.0\n",
      "totalReward =  6.0\n",
      "done =  False\n",
      "\n",
      "7 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.0145544   0.24056953  0.00399852 -0.2174413 ]\n",
      "reward =  1.0\n",
      "totalReward =  7.0\n",
      "done =  False\n",
      "\n",
      "8 : --------------------------\n",
      "action =  1\n",
      "observation =  [-9.7430041e-03  4.3563411e-01 -3.5030421e-04 -5.0886023e-01]\n",
      "reward =  1.0\n",
      "totalReward =  8.0\n",
      "done =  False\n",
      "\n",
      "9 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00103032  0.24051708 -0.01052751 -0.21628773]\n",
      "reward =  1.0\n",
      "totalReward =  9.0\n",
      "done =  False\n",
      "\n",
      "10 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00378002  0.0455472  -0.01485326  0.07305585]\n",
      "reward =  1.0\n",
      "totalReward =  10.0\n",
      "done =  False\n",
      "\n",
      "11 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00469096  0.24087891 -0.01339215 -0.2242761 ]\n",
      "reward =  1.0\n",
      "totalReward =  11.0\n",
      "done =  False\n",
      "\n",
      "12 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00950854  0.04595089 -0.01787767  0.06415253]\n",
      "reward =  1.0\n",
      "totalReward =  12.0\n",
      "done =  False\n",
      "\n",
      "13 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01042756  0.24132454 -0.01659462 -0.23411687]\n",
      "reward =  1.0\n",
      "totalReward =  13.0\n",
      "done =  False\n",
      "\n",
      "14 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01525405  0.04644358 -0.02127696  0.05328574]\n",
      "reward =  1.0\n",
      "totalReward =  14.0\n",
      "done =  False\n",
      "\n",
      "15 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01618292  0.24186406 -0.02021124 -0.24603356]\n",
      "reward =  1.0\n",
      "totalReward =  15.0\n",
      "done =  False\n",
      "\n",
      "16 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0210202   0.04703651 -0.02513191  0.04020635]\n",
      "reward =  1.0\n",
      "totalReward =  16.0\n",
      "done =  False\n",
      "\n",
      "17 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.02196093  0.24250966 -0.02432778 -0.2602988 ]\n",
      "reward =  1.0\n",
      "totalReward =  17.0\n",
      "done =  False\n",
      "\n",
      "18 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.02681113  0.04774329 -0.02953376  0.02461265]\n",
      "reward =  1.0\n",
      "totalReward =  18.0\n",
      "done =  False\n",
      "\n",
      "19 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.02776599  0.24327606 -0.02904151 -0.27724028]\n",
      "reward =  1.0\n",
      "totalReward =  19.0\n",
      "done =  False\n",
      "\n",
      "20 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.03263151  0.04858021 -0.03458631  0.00614337]\n",
      "reward =  1.0\n",
      "totalReward =  20.0\n",
      "done =  False\n",
      "\n",
      "21 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.03360312  0.24418066 -0.03446345 -0.2972482 ]\n",
      "reward =  1.0\n",
      "totalReward =  21.0\n",
      "done =  False\n",
      "\n",
      "22 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.03848673  0.04956652 -0.04040841 -0.01563057]\n",
      "reward =  1.0\n",
      "totalReward =  22.0\n",
      "done =  False\n",
      "\n",
      "23 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.03947806 -0.14495333 -0.04072102  0.26403418]\n",
      "reward =  1.0\n",
      "totalReward =  23.0\n",
      "done =  False\n",
      "\n",
      "24 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.03657899  0.05072548 -0.03544034 -0.04120938]\n",
      "reward =  1.0\n",
      "totalReward =  24.0\n",
      "done =  False\n",
      "\n",
      "25 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0375935  -0.14387082 -0.03626452  0.24008448]\n",
      "reward =  1.0\n",
      "totalReward =  25.0\n",
      "done =  False\n",
      "\n",
      "26 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.03471609  0.05174991 -0.03146284 -0.06381311]\n",
      "reward =  1.0\n",
      "totalReward =  26.0\n",
      "done =  False\n",
      "\n",
      "27 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.03575109 -0.14290714 -0.0327391   0.21877941]\n",
      "reward =  1.0\n",
      "totalReward =  27.0\n",
      "done =  False\n",
      "\n",
      "28 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.03289294  0.05266714 -0.02836351 -0.08404838]\n",
      "reward =  1.0\n",
      "totalReward =  28.0\n",
      "done =  False\n",
      "\n",
      "29 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.03394629 -0.14203699 -0.03004448  0.1995526 ]\n",
      "reward =  1.0\n",
      "totalReward =  29.0\n",
      "done =  False\n",
      "\n",
      "30 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.03110555  0.0535015  -0.02605342 -0.10245452]\n",
      "reward =  1.0\n",
      "totalReward =  30.0\n",
      "done =  False\n",
      "\n",
      "31 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.03217557 -0.14123757 -0.02810252  0.18189612]\n",
      "reward =  1.0\n",
      "totalReward =  31.0\n",
      "done =  False\n",
      "\n",
      "32 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.02935082  0.054275   -0.02446459 -0.11951799]\n",
      "reward =  1.0\n",
      "totalReward =  32.0\n",
      "done =  False\n",
      "\n",
      "33 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.03043632 -0.14048804 -0.02685495  0.16534728]\n",
      "reward =  1.0\n",
      "totalReward =  33.0\n",
      "done =  False\n",
      "\n",
      "34 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.02762656  0.05500783 -0.02354801 -0.1356852 ]\n",
      "reward =  1.0\n",
      "totalReward =  34.0\n",
      "done =  False\n",
      "\n",
      "35 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.02872672 -0.13976906 -0.02626171  0.14947665]\n",
      "reward =  1.0\n",
      "totalReward =  35.0\n",
      "done =  False\n",
      "\n",
      "36 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.02593134 -0.3345053  -0.02327218  0.43376023]\n",
      "reward =  1.0\n",
      "totalReward =  36.0\n",
      "done =  False\n",
      "\n",
      "37 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01924123 -0.13906172 -0.01459697  0.13383286]\n",
      "reward =  1.0\n",
      "totalReward =  37.0\n",
      "done =  False\n",
      "\n",
      "38 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01646    -0.3339716  -0.01192032  0.42187512]\n",
      "reward =  1.0\n",
      "totalReward =  38.0\n",
      "done =  False\n",
      "\n",
      "39 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00978057 -0.1386828  -0.00348281  0.12545827]\n",
      "reward =  1.0\n",
      "totalReward =  39.0\n",
      "done =  False\n",
      "\n",
      "40 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00700691 -0.3337547  -0.00097365  0.41704038]\n",
      "reward =  1.0\n",
      "totalReward =  40.0\n",
      "done =  False\n",
      "\n",
      "41 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00033182 -0.13861895  0.00736716  0.12405065]\n",
      "reward =  1.0\n",
      "totalReward =  41.0\n",
      "done =  False\n",
      "\n",
      "42 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00244056  0.0563967   0.00984817 -0.16629893]\n",
      "reward =  1.0\n",
      "totalReward =  42.0\n",
      "done =  False\n",
      "\n",
      "43 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00131263 -0.13886483  0.00652219  0.12947448]\n",
      "reward =  1.0\n",
      "totalReward =  43.0\n",
      "done =  False\n",
      "\n",
      "44 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00408992  0.05616308  0.00911168 -0.16114368]\n",
      "reward =  1.0\n",
      "totalReward =  44.0\n",
      "done =  False\n",
      "\n",
      "45 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00296666 -0.13908812  0.00588881  0.13439977]\n",
      "reward =  1.0\n",
      "totalReward =  45.0\n",
      "done =  False\n",
      "\n",
      "46 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00574842  0.05594899  0.0085768  -0.15641952]\n",
      "reward =  1.0\n",
      "totalReward =  46.0\n",
      "done =  False\n",
      "\n",
      "47 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00462944 -0.1392947   0.00544841  0.1389568 ]\n",
      "reward =  1.0\n",
      "totalReward =  47.0\n",
      "done =  False\n",
      "\n",
      "48 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00741534  0.05574879  0.00822755 -0.15200227]\n",
      "reward =  1.0\n",
      "totalReward =  48.0\n",
      "done =  False\n",
      "\n",
      "49 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00630036 -0.13949     0.0051875   0.14326487]\n",
      "reward =  1.0\n",
      "totalReward =  49.0\n",
      "done =  False\n",
      "\n",
      "50 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00909016  0.05555728  0.0080528  -0.14777698]\n",
      "reward =  1.0\n",
      "totalReward =  50.0\n",
      "done =  False\n",
      "\n",
      "51 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00797902 -0.13967906  0.00509726  0.14743553]\n",
      "reward =  1.0\n",
      "totalReward =  51.0\n",
      "done =  False\n",
      "\n",
      "52 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.0107726   0.05536953  0.00804597 -0.14363496]\n",
      "reward =  1.0\n",
      "totalReward =  52.0\n",
      "done =  False\n",
      "\n",
      "53 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00966521 -0.13986672  0.00517327  0.15157542]\n",
      "reward =  1.0\n",
      "totalReward =  53.0\n",
      "done =  False\n",
      "\n",
      "54 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01246254  0.05518077  0.00820478 -0.13947096]\n",
      "reward =  1.0\n",
      "totalReward =  54.0\n",
      "done =  False\n",
      "\n",
      "55 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.01135893 -0.14005773  0.00541536  0.15578909]\n",
      "reward =  1.0\n",
      "totalReward =  55.0\n",
      "done =  False\n",
      "\n",
      "56 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01416008  0.05498627  0.00853114 -0.1351805 ]\n",
      "reward =  1.0\n",
      "totalReward =  56.0\n",
      "done =  False\n",
      "\n",
      "57 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.01306036 -0.14025684  0.00582753  0.16018163]\n",
      "reward =  1.0\n",
      "totalReward =  57.0\n",
      "done =  False\n",
      "\n",
      "58 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01586549  0.05478121  0.00903117 -0.13065718]\n",
      "reward =  1.0\n",
      "totalReward =  58.0\n",
      "done =  False\n",
      "\n",
      "59 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.01476987 -0.14046894  0.00641802  0.16486122]\n",
      "reward =  1.0\n",
      "totalReward =  59.0\n",
      "done =  False\n",
      "\n",
      "60 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01757925  0.05456055  0.00971525 -0.1257901 ]\n",
      "reward =  1.0\n",
      "totalReward =  60.0\n",
      "done =  False\n",
      "\n",
      "61 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.01648804 -0.14069922  0.00719945  0.16994198]\n",
      "reward =  1.0\n",
      "totalReward =  61.0\n",
      "done =  False\n",
      "\n",
      "62 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01930202  0.05431895  0.01059829 -0.12046108]\n",
      "reward =  1.0\n",
      "totalReward =  62.0\n",
      "done =  False\n",
      "\n",
      "63 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.01821564 -0.14095324  0.00818906  0.17554659]\n",
      "reward =  1.0\n",
      "totalReward =  63.0\n",
      "done =  False\n",
      "\n",
      "64 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.02103471  0.05405057  0.0117     -0.11454175]\n",
      "reward =  1.0\n",
      "totalReward =  64.0\n",
      "done =  False\n",
      "\n",
      "65 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.0199537  -0.14123707  0.00940916  0.18180935]\n",
      "reward =  1.0\n",
      "totalReward =  65.0\n",
      "done =  False\n",
      "\n",
      "66 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.02277844  0.053749    0.01304535 -0.10789054]\n",
      "reward =  1.0\n",
      "totalReward =  66.0\n",
      "done =  False\n",
      "\n",
      "67 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.02170346 -0.14155744  0.01088754  0.18887942]\n",
      "reward =  1.0\n",
      "totalReward =  67.0\n",
      "done =  False\n",
      "\n",
      "68 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.02453461  0.05340707  0.01466513 -0.10034914]\n",
      "reward =  1.0\n",
      "totalReward =  68.0\n",
      "done =  False\n",
      "\n",
      "69 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.02346646 -0.14192195  0.01265814  0.19692428]\n",
      "reward =  1.0\n",
      "totalReward =  69.0\n",
      "done =  False\n",
      "\n",
      "70 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.0263049   0.05301667  0.01659663 -0.09173884]\n",
      "reward =  1.0\n",
      "totalReward =  70.0\n",
      "done =  False\n",
      "\n",
      "71 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.02524457 -0.14233918  0.01476185  0.20613377]\n",
      "reward =  1.0\n",
      "totalReward =  71.0\n",
      "done =  False\n",
      "\n",
      "72 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.02809135  0.0525686   0.01888453 -0.08185622]\n",
      "reward =  1.0\n",
      "totalReward =  72.0\n",
      "done =  False\n",
      "\n",
      "73 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.02703998 -0.1428189   0.0172474   0.21672449]\n",
      "reward =  1.0\n",
      "totalReward =  73.0\n",
      "done =  False\n",
      "\n",
      "74 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.02989636  0.0520523   0.02158189 -0.07046834]\n",
      "reward =  1.0\n",
      "totalReward =  74.0\n",
      "done =  False\n",
      "\n",
      "75 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.02885531 -0.14337231  0.02017253  0.22894488]\n",
      "reward =  1.0\n",
      "totalReward =  75.0\n",
      "done =  False\n",
      "\n",
      "76 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.03172276  0.05145565  0.02475142 -0.05730727]\n",
      "reward =  1.0\n",
      "totalReward =  76.0\n",
      "done =  False\n",
      "\n",
      "77 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.03069365 -0.14401229  0.02360528  0.243081  ]\n",
      "reward =  1.0\n",
      "totalReward =  77.0\n",
      "done =  False\n",
      "\n",
      "78 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.03357389  0.05076468  0.0284669  -0.04206374]\n",
      "reward =  1.0\n",
      "totalReward =  78.0\n",
      "done =  False\n",
      "\n",
      "79 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.0325586   0.2454671   0.02762562 -0.3256309 ]\n",
      "reward =  1.0\n",
      "totalReward =  79.0\n",
      "done =  False\n",
      "\n",
      "80 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.02764926  0.04996293  0.021113   -0.02436565]\n",
      "reward =  1.0\n",
      "totalReward =  80.0\n",
      "done =  False\n",
      "\n",
      "81 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.02665     0.24477583  0.02062569 -0.31031314]\n",
      "reward =  1.0\n",
      "totalReward =  81.0\n",
      "done =  False\n",
      "\n",
      "82 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.02175448  0.04936619  0.01441943 -0.01119747]\n",
      "reward =  1.0\n",
      "totalReward =  82.0\n",
      "done =  False\n",
      "\n",
      "83 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.02076716  0.2442784   0.01419548 -0.29929623]\n",
      "reward =  1.0\n",
      "totalReward =  83.0\n",
      "done =  False\n",
      "\n",
      "84 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.01588159  0.04895702  0.00820955 -0.00217035]\n",
      "reward =  1.0\n",
      "totalReward =  84.0\n",
      "done =  False\n",
      "\n",
      "85 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01490245  0.24396028  0.00816615 -0.2922518 ]\n",
      "reward =  1.0\n",
      "totalReward =  85.0\n",
      "done =  False\n",
      "\n",
      "86 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.01002324  0.04872285  0.00232111  0.0029954 ]\n",
      "reward =  1.0\n",
      "totalReward =  86.0\n",
      "done =  False\n",
      "\n",
      "87 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00904879  0.24381143  0.00238102 -0.2889543 ]\n",
      "reward =  1.0\n",
      "totalReward =  87.0\n",
      "done =  False\n",
      "\n",
      "88 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00417256  0.04865561 -0.00339807  0.00447864]\n",
      "reward =  1.0\n",
      "totalReward =  88.0\n",
      "done =  False\n",
      "\n",
      "89 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00319945  0.24382614 -0.00330849 -0.28927448]\n",
      "reward =  1.0\n",
      "totalReward =  89.0\n",
      "done =  False\n",
      "\n",
      "90 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00167708  0.04875151 -0.00909398  0.00236315]\n",
      "reward =  1.0\n",
      "totalReward =  90.0\n",
      "done =  False\n",
      "\n",
      "91 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00265211  0.2440027  -0.00904672 -0.2931751 ]\n",
      "reward =  1.0\n",
      "totalReward =  91.0\n",
      "done =  False\n",
      "\n",
      "92 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00753216  0.04901089 -0.01491022 -0.00335907]\n",
      "reward =  1.0\n",
      "totalReward =  92.0\n",
      "done =  False\n",
      "\n",
      "93 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00851238  0.24434347 -0.0149774  -0.3007088 ]\n",
      "reward =  1.0\n",
      "totalReward =  93.0\n",
      "done =  False\n",
      "\n",
      "94 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01339925  0.04943816 -0.02099158 -0.01278683]\n",
      "reward =  1.0\n",
      "totalReward =  94.0\n",
      "done =  False\n",
      "\n",
      "95 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01438801  0.24485478 -0.02124732 -0.31201825]\n",
      "reward =  1.0\n",
      "totalReward =  95.0\n",
      "done =  False\n",
      "\n",
      "96 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01928511  0.05004186 -0.02748768 -0.02611107]\n",
      "reward =  1.0\n",
      "totalReward =  96.0\n",
      "done =  False\n",
      "\n",
      "97 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.02028594 -0.14467533 -0.0280099   0.25777403]\n",
      "reward =  1.0\n",
      "totalReward =  97.0\n",
      "done =  False\n",
      "\n",
      "98 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01739244  0.05083508 -0.02285442 -0.04361039]\n",
      "reward =  1.0\n",
      "totalReward =  98.0\n",
      "done =  False\n",
      "\n",
      "99 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01840914 -0.14395182 -0.02372663  0.24177504]\n",
      "reward =  1.0\n",
      "totalReward =  99.0\n",
      "done =  False\n",
      "\n",
      "100 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0155301   0.05150088 -0.01889113 -0.05829646]\n",
      "reward =  1.0\n",
      "totalReward =  100.0\n",
      "done =  False\n",
      "\n",
      "101 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01656012 -0.14334519 -0.02005706  0.22836682]\n",
      "reward =  1.0\n",
      "totalReward =  101.0\n",
      "done =  False\n",
      "\n",
      "102 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01369322  0.05205756 -0.01548972 -0.07057473]\n",
      "reward =  1.0\n",
      "totalReward =  102.0\n",
      "done =  False\n",
      "\n",
      "103 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01473437 -0.14283894 -0.01690122  0.21718115]\n",
      "reward =  1.0\n",
      "totalReward =  103.0\n",
      "done =  False\n",
      "\n",
      "104 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01187759  0.0525205  -0.01255759 -0.08078487]\n",
      "reward =  1.0\n",
      "totalReward =  104.0\n",
      "done =  False\n",
      "\n",
      "105 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.012928   -0.1424192  -0.01417329  0.2079098 ]\n",
      "reward =  1.0\n",
      "totalReward =  105.0\n",
      "done =  False\n",
      "\n",
      "106 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01007961  0.05290251 -0.0100151  -0.08921017]\n",
      "reward =  1.0\n",
      "totalReward =  106.0\n",
      "done =  False\n",
      "\n",
      "107 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01113767 -0.14207447 -0.0117993   0.20029624]\n",
      "reward =  1.0\n",
      "totalReward =  107.0\n",
      "done =  False\n",
      "\n",
      "108 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00829618  0.05321424 -0.00779337 -0.09608533]\n",
      "reward =  1.0\n",
      "totalReward =  108.0\n",
      "done =  False\n",
      "\n",
      "109 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00936046 -0.14179516 -0.00971508  0.19412865]\n",
      "reward =  1.0\n",
      "totalReward =  109.0\n",
      "done =  False\n",
      "\n",
      "110 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00652456  0.05346441 -0.00583251 -0.10160308]\n",
      "reward =  1.0\n",
      "totalReward =  110.0\n",
      "done =  False\n",
      "\n",
      "111 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00759385 -0.14157346 -0.00786457  0.18923402]\n",
      "reward =  1.0\n",
      "totalReward =  111.0\n",
      "done =  False\n",
      "\n",
      "112 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00476238  0.05366011 -0.00407989 -0.10591945]\n",
      "reward =  1.0\n",
      "totalReward =  112.0\n",
      "done =  False\n",
      "\n",
      "113 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00583558 -0.14140314 -0.00619828  0.1854735 ]\n",
      "reward =  1.0\n",
      "totalReward =  113.0\n",
      "done =  False\n",
      "\n",
      "114 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00300752  0.05380695 -0.00248881 -0.10915828]\n",
      "reward =  1.0\n",
      "totalReward =  114.0\n",
      "done =  False\n",
      "\n",
      "115 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00408365 -0.14127925 -0.00467197  0.18273841]\n",
      "reward =  1.0\n",
      "totalReward =  115.0\n",
      "done =  False\n",
      "\n",
      "116 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00125807  0.05390924 -0.00101721 -0.11141469]\n",
      "reward =  1.0\n",
      "totalReward =  116.0\n",
      "done =  False\n",
      "\n",
      "117 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00233625 -0.14119813 -0.0032455   0.18094714]\n",
      "reward =  1.0\n",
      "totalReward =  117.0\n",
      "done =  False\n",
      "\n",
      "118 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00048771  0.05397012  0.00037344 -0.11275785]\n",
      "reward =  1.0\n",
      "totalReward =  118.0\n",
      "done =  False\n",
      "\n",
      "119 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00059169 -0.14115718 -0.00188171  0.18004286]\n",
      "reward =  1.0\n",
      "totalReward =  119.0\n",
      "done =  False\n",
      "\n",
      "120 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00223145  0.05399165  0.00171914 -0.11323308]\n",
      "reward =  1.0\n",
      "totalReward =  120.0\n",
      "done =  False\n",
      "\n",
      "121 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00115162 -0.1411549  -0.00054552  0.17999174]\n",
      "reward =  1.0\n",
      "totalReward =  121.0\n",
      "done =  False\n",
      "\n",
      "122 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00397471  0.05397486  0.00305432 -0.11286324]\n",
      "reward =  1.0\n",
      "totalReward =  122.0\n",
      "done =  False\n",
      "\n",
      "123 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00289522 -0.14119072  0.00079705  0.18078174]\n",
      "reward =  1.0\n",
      "totalReward =  123.0\n",
      "done =  False\n",
      "\n",
      "124 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00571903  0.05391981  0.00441269 -0.11164964]\n",
      "reward =  1.0\n",
      "totalReward =  124.0\n",
      "done =  False\n",
      "\n",
      "125 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00464064 -0.1412651   0.00217969  0.18242219]\n",
      "reward =  1.0\n",
      "totalReward =  125.0\n",
      "done =  False\n",
      "\n",
      "126 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00746594  0.0538256   0.00582814 -0.10957233]\n",
      "reward =  1.0\n",
      "totalReward =  126.0\n",
      "done =  False\n",
      "\n",
      "127 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00638942 -0.14137937  0.00363669  0.18494363]\n",
      "reward =  1.0\n",
      "totalReward =  127.0\n",
      "done =  False\n",
      "\n",
      "128 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00921701  0.05369035  0.00733556 -0.10658984]\n",
      "reward =  1.0\n",
      "totalReward =  128.0\n",
      "done =  False\n",
      "\n",
      "129 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00814321 -0.14153595  0.00520377  0.18839836]\n",
      "reward =  1.0\n",
      "totalReward =  129.0\n",
      "done =  False\n",
      "\n",
      "130 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01097392  0.05351117  0.00897173 -0.10263845]\n",
      "reward =  1.0\n",
      "totalReward =  130.0\n",
      "done =  False\n",
      "\n",
      "131 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.0099037  -0.1417382   0.00691897  0.19286148]\n",
      "reward =  1.0\n",
      "totalReward =  131.0\n",
      "done =  False\n",
      "\n",
      "132 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01273846  0.05328409  0.0107762  -0.0976308 ]\n",
      "reward =  1.0\n",
      "totalReward =  132.0\n",
      "done =  False\n",
      "\n",
      "133 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.01167278 -0.14199063  0.00882358  0.19843242]\n",
      "reward =  1.0\n",
      "totalReward =  133.0\n",
      "done =  False\n",
      "\n",
      "134 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.0145126   0.05300401  0.01279223 -0.09145406]\n",
      "reward =  1.0\n",
      "totalReward =  134.0\n",
      "done =  False\n",
      "\n",
      "135 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.01345252 -0.14229894  0.01096315  0.20523721]\n",
      "reward =  1.0\n",
      "totalReward =  135.0\n",
      "done =  False\n",
      "\n",
      "136 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01629849  0.05266453  0.01506789 -0.08396733]\n",
      "reward =  1.0\n",
      "totalReward =  136.0\n",
      "done =  False\n",
      "\n",
      "137 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.0152452  -0.14267012  0.01338854  0.2134312 ]\n",
      "reward =  1.0\n",
      "totalReward =  137.0\n",
      "done =  False\n",
      "\n",
      "138 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01809861  0.05225787  0.01765717 -0.07499848]\n",
      "reward =  1.0\n",
      "totalReward =  138.0\n",
      "done =  False\n",
      "\n",
      "139 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.01705345 -0.1431127   0.0161572   0.22320263]\n",
      "reward =  1.0\n",
      "totalReward =  139.0\n",
      "done =  False\n",
      "\n",
      "140 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.0199157   0.05177463  0.02062125 -0.0643402 ]\n",
      "reward =  1.0\n",
      "totalReward =  140.0\n",
      "done =  False\n",
      "\n",
      "141 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01888021  0.24659495  0.01933445 -0.35044634]\n",
      "reward =  1.0\n",
      "totalReward =  141.0\n",
      "done =  False\n",
      "\n",
      "142 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.01394831  0.05120344  0.01232552 -0.05172988]\n",
      "reward =  1.0\n",
      "totalReward =  142.0\n",
      "done =  False\n",
      "\n",
      "143 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.01292424  0.24614652  0.01129092 -0.34049866]\n",
      "reward =  1.0\n",
      "totalReward =  143.0\n",
      "done =  False\n",
      "\n",
      "144 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00800131  0.05086574  0.00448095 -0.04427671]\n",
      "reward =  1.0\n",
      "totalReward =  144.0\n",
      "done =  False\n",
      "\n",
      "145 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.006984    0.24592316  0.00359542 -0.3355425 ]\n",
      "reward =  1.0\n",
      "totalReward =  145.0\n",
      "done =  False\n",
      "\n",
      "146 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00206553  0.05075022 -0.00311543 -0.04172794]\n",
      "reward =  1.0\n",
      "totalReward =  146.0\n",
      "done =  False\n",
      "\n",
      "147 : --------------------------\n",
      "action =  0\n",
      "observation =  [-0.00105053 -0.14432691 -0.00394999  0.2499704 ]\n",
      "reward =  1.0\n",
      "totalReward =  147.0\n",
      "done =  False\n",
      "\n",
      "148 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00393707  0.05085122  0.00104942 -0.0439558 ]\n",
      "reward =  1.0\n",
      "totalReward =  148.0\n",
      "done =  False\n",
      "\n",
      "149 : --------------------------\n",
      "action =  1\n",
      "observation =  [-2.9200437e-03  2.4595810e-01  1.7029924e-04 -3.3630744e-01]\n",
      "reward =  1.0\n",
      "totalReward =  149.0\n",
      "done =  False\n",
      "\n",
      "150 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00199912  0.05083373 -0.00655585 -0.04357082]\n",
      "reward =  1.0\n",
      "totalReward =  150.0\n",
      "done =  False\n",
      "\n",
      "151 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00301579 -0.1441936  -0.00742727  0.24703649]\n",
      "reward =  1.0\n",
      "totalReward =  151.0\n",
      "done =  False\n",
      "\n",
      "152 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00013192  0.05103363 -0.00248654 -0.04797988]\n",
      "reward =  1.0\n",
      "totalReward =  152.0\n",
      "done =  False\n",
      "\n",
      "153 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00115259 -0.14405258 -0.00344613  0.24391748]\n",
      "reward =  1.0\n",
      "totalReward =  153.0\n",
      "done =  False\n",
      "\n",
      "154 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00172846  0.05111843  0.00143222 -0.04985045]\n",
      "reward =  1.0\n",
      "totalReward =  154.0\n",
      "done =  False\n",
      "\n",
      "155 : --------------------------\n",
      "action =  1\n",
      "observation =  [-0.00070609  0.24621981  0.00043521 -0.34208116]\n",
      "reward =  1.0\n",
      "totalReward =  155.0\n",
      "done =  False\n",
      "\n",
      "156 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00421831  0.05109167 -0.00640642 -0.04926102]\n",
      "reward =  1.0\n",
      "totalReward =  156.0\n",
      "done =  False\n",
      "\n",
      "157 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00524014 -0.14393783 -0.00739164  0.24139376]\n",
      "reward =  1.0\n",
      "totalReward =  157.0\n",
      "done =  False\n",
      "\n",
      "158 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00236138  0.05128892 -0.00256376 -0.05361149]\n",
      "reward =  1.0\n",
      "totalReward =  158.0\n",
      "done =  False\n",
      "\n",
      "159 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00338716 -0.14379618 -0.00363599  0.23826145]\n",
      "reward =  1.0\n",
      "totalReward =  159.0\n",
      "done =  False\n",
      "\n",
      "160 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00051124  0.05137753  0.00112924 -0.05556615]\n",
      "reward =  1.0\n",
      "totalReward =  160.0\n",
      "done =  False\n",
      "\n",
      "161 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 1.5387896e-03  2.4648327e-01  1.7914455e-05 -3.4789258e-01]\n",
      "reward =  1.0\n",
      "totalReward =  161.0\n",
      "done =  False\n",
      "\n",
      "162 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00646846  0.05136107 -0.00693994 -0.05520401]\n",
      "reward =  1.0\n",
      "totalReward =  162.0\n",
      "done =  False\n",
      "\n",
      "163 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00749568 -0.1436607  -0.00804402  0.23528126]\n",
      "reward =  1.0\n",
      "totalReward =  163.0\n",
      "done =  False\n",
      "\n",
      "164 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00462246  0.05157526 -0.00333839 -0.05992811]\n",
      "reward =  1.0\n",
      "totalReward =  164.0\n",
      "done =  False\n",
      "\n",
      "165 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00565397 -0.14349867 -0.00453695  0.23169966]\n",
      "reward =  1.0\n",
      "totalReward =  165.0\n",
      "done =  False\n",
      "\n",
      "166 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 2.7839944e-03  5.1687818e-02  9.7038952e-05 -6.2410906e-02]\n",
      "reward =  1.0\n",
      "totalReward =  166.0\n",
      "done =  False\n",
      "\n",
      "167 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00381775 -0.14343552 -0.00115118  0.23030263]\n",
      "reward =  1.0\n",
      "totalReward =  167.0\n",
      "done =  False\n",
      "\n",
      "168 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00094904  0.05170286  0.00345487 -0.06274319]\n",
      "reward =  1.0\n",
      "totalReward =  168.0\n",
      "done =  False\n",
      "\n",
      "169 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0019831   0.2467751   0.00220001 -0.3543341 ]\n",
      "reward =  1.0\n",
      "totalReward =  169.0\n",
      "done =  False\n",
      "\n",
      "170 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0069186   0.05162194 -0.00488667 -0.06095824]\n",
      "reward =  1.0\n",
      "totalReward =  170.0\n",
      "done =  False\n",
      "\n",
      "171 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00795104 -0.1434296  -0.00610584  0.23017891]\n",
      "reward =  1.0\n",
      "totalReward =  171.0\n",
      "done =  False\n",
      "\n",
      "172 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00508245  0.05177906 -0.00150226 -0.06442374]\n",
      "reward =  1.0\n",
      "totalReward =  172.0\n",
      "done =  False\n",
      "\n",
      "173 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00611803 -0.14332132 -0.00279073  0.22778484]\n",
      "reward =  1.0\n",
      "totalReward =  173.0\n",
      "done =  False\n",
      "\n",
      "174 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0032516   0.0518404   0.00176496 -0.06577709]\n",
      "reward =  1.0\n",
      "totalReward =  174.0\n",
      "done =  False\n",
      "\n",
      "175 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00428841 -0.1433068   0.00044942  0.22746217]\n",
      "reward =  1.0\n",
      "totalReward =  175.0\n",
      "done =  False\n",
      "\n",
      "176 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00142227  0.05180871  0.00499866 -0.06507895]\n",
      "reward =  1.0\n",
      "totalReward =  176.0\n",
      "done =  False\n",
      "\n",
      "177 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00245845  0.24685864  0.00369709 -0.35618058]\n",
      "reward =  1.0\n",
      "totalReward =  177.0\n",
      "done =  False\n",
      "\n",
      "178 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00739562  0.05168432 -0.00342653 -0.06233417]\n",
      "reward =  1.0\n",
      "totalReward =  178.0\n",
      "done =  False\n",
      "\n",
      "179 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00842931 -0.14338833 -0.00467321  0.2292657 ]\n",
      "reward =  1.0\n",
      "totalReward =  179.0\n",
      "done =  False\n",
      "\n",
      "180 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 5.5615399e-03  5.1800087e-02 -8.7895191e-05 -6.4887650e-02]\n",
      "reward =  1.0\n",
      "totalReward =  180.0\n",
      "done =  False\n",
      "\n",
      "181 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00659754 -0.1433206  -0.00138565  0.22776754]\n",
      "reward =  1.0\n",
      "totalReward =  181.0\n",
      "done =  False\n",
      "\n",
      "182 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00373113  0.05182112  0.0031697  -0.06535214]\n",
      "reward =  1.0\n",
      "totalReward =  182.0\n",
      "done =  False\n",
      "\n",
      "183 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00476755  0.24689749  0.00186266 -0.35703334]\n",
      "reward =  1.0\n",
      "totalReward =  183.0\n",
      "done =  False\n",
      "\n",
      "184 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0097055   0.0517491  -0.00527801 -0.06376364]\n",
      "reward =  1.0\n",
      "totalReward =  184.0\n",
      "done =  False\n",
      "\n",
      "185 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01074048 -0.14329678 -0.00655328  0.22724938]\n",
      "reward =  1.0\n",
      "totalReward =  185.0\n",
      "done =  False\n",
      "\n",
      "186 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00787455  0.05191821 -0.00200829 -0.06749346]\n",
      "reward =  1.0\n",
      "totalReward =  186.0\n",
      "done =  False\n",
      "\n",
      "187 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00891291 -0.14317489 -0.00335816  0.22455516]\n",
      "reward =  1.0\n",
      "totalReward =  187.0\n",
      "done =  False\n",
      "\n",
      "188 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00604941  0.05199489  0.00113294 -0.06918517]\n",
      "reward =  1.0\n",
      "totalReward =  188.0\n",
      "done =  False\n",
      "\n",
      "189 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00708931 -0.14314328 -0.00025076  0.22385499]\n",
      "reward =  1.0\n",
      "totalReward =  189.0\n",
      "done =  False\n",
      "\n",
      "190 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00422645  0.05198225  0.00422634 -0.06890702]\n",
      "reward =  1.0\n",
      "totalReward =  190.0\n",
      "done =  False\n",
      "\n",
      "191 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00526609  0.24704336  0.0028482  -0.3602535 ]\n",
      "reward =  1.0\n",
      "totalReward =  191.0\n",
      "done =  False\n",
      "\n",
      "192 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01020696  0.05188104 -0.00435687 -0.06667386]\n",
      "reward =  1.0\n",
      "totalReward =  192.0\n",
      "done =  False\n",
      "\n",
      "193 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01124458 -0.14317818 -0.00569035  0.22463126]\n",
      "reward =  1.0\n",
      "totalReward =  193.0\n",
      "done =  False\n",
      "\n",
      "194 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00838102  0.05202464 -0.00119772 -0.06984116]\n",
      "reward =  1.0\n",
      "totalReward =  194.0\n",
      "done =  False\n",
      "\n",
      "195 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00942151 -0.14308013 -0.00259455  0.22246364]\n",
      "reward =  1.0\n",
      "totalReward =  195.0\n",
      "done =  False\n",
      "\n",
      "196 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00655991  0.05207881  0.00185473 -0.07103658]\n",
      "reward =  1.0\n",
      "totalReward =  196.0\n",
      "done =  False\n",
      "\n",
      "197 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00760148  0.24717413  0.00043399 -0.36313376]\n",
      "reward =  1.0\n",
      "totalReward =  197.0\n",
      "done =  False\n",
      "\n",
      "198 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01254497  0.05204601 -0.00682868 -0.07031402]\n",
      "reward =  1.0\n",
      "totalReward =  198.0\n",
      "done =  False\n",
      "\n",
      "199 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01358589 -0.14297737 -0.00823496  0.22020663]\n",
      "reward =  1.0\n",
      "totalReward =  199.0\n",
      "done =  False\n",
      "\n",
      "200 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01072634  0.05226131 -0.00383083 -0.07506253]\n",
      "reward =  1.0\n",
      "totalReward =  200.0\n",
      "done =  False\n",
      "\n",
      "201 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01177156 -0.14280552 -0.00533208  0.2164093 ]\n",
      "reward =  1.0\n",
      "totalReward =  201.0\n",
      "done =  False\n",
      "\n",
      "202 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00891545  0.05239226 -0.00100389 -0.07795082]\n",
      "reward =  1.0\n",
      "totalReward =  202.0\n",
      "done =  False\n",
      "\n",
      "203 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0099633  -0.14271529 -0.00256291  0.21441521]\n",
      "reward =  1.0\n",
      "totalReward =  203.0\n",
      "done =  False\n",
      "\n",
      "204 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00710899  0.05244321  0.00172539 -0.07907508]\n",
      "reward =  1.0\n",
      "totalReward =  204.0\n",
      "done =  False\n",
      "\n",
      "205 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 8.1578577e-03 -1.4270343e-01  1.4389228e-04  2.1415173e-01]\n",
      "reward =  1.0\n",
      "totalReward =  205.0\n",
      "done =  False\n",
      "\n",
      "206 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00530379  0.05241646  0.00442693 -0.07848581]\n",
      "reward =  1.0\n",
      "totalReward =  206.0\n",
      "done =  False\n",
      "\n",
      "207 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00635212 -0.14276867  0.00285721  0.21559054]\n",
      "reward =  1.0\n",
      "totalReward =  207.0\n",
      "done =  False\n",
      "\n",
      "208 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00349674  0.05231231  0.00716902 -0.07618974]\n",
      "reward =  1.0\n",
      "totalReward =  208.0\n",
      "done =  False\n",
      "\n",
      "209 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00454299  0.24733077  0.00564523 -0.3666022 ]\n",
      "reward =  1.0\n",
      "totalReward =  209.0\n",
      "done =  False\n",
      "\n",
      "210 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00948961  0.05212905 -0.00168682 -0.07214463]\n",
      "reward =  1.0\n",
      "totalReward =  210.0\n",
      "done =  False\n",
      "\n",
      "211 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01053219 -0.14296868 -0.00312971  0.22000563]\n",
      "reward =  1.0\n",
      "totalReward =  211.0\n",
      "done =  False\n",
      "\n",
      "212 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00767281  0.05219787  0.0012704  -0.07366289]\n",
      "reward =  1.0\n",
      "totalReward =  212.0\n",
      "done =  False\n",
      "\n",
      "213 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 8.7167714e-03 -1.4294228e-01 -2.0285600e-04  2.1942058e-01]\n",
      "reward =  1.0\n",
      "totalReward =  213.0\n",
      "done =  False\n",
      "\n",
      "214 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00585793  0.05218258  0.00418556 -0.07332633]\n",
      "reward =  1.0\n",
      "totalReward =  214.0\n",
      "done =  False\n",
      "\n",
      "215 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00690158  0.24724427  0.00271903 -0.36468577]\n",
      "reward =  1.0\n",
      "totalReward =  215.0\n",
      "done =  False\n",
      "\n",
      "216 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01184646  0.05208379 -0.00457469 -0.07114672]\n",
      "reward =  1.0\n",
      "totalReward =  216.0\n",
      "done =  False\n",
      "\n",
      "217 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01288814 -0.14297228 -0.00599762  0.22008936]\n",
      "reward =  1.0\n",
      "totalReward =  217.0\n",
      "done =  False\n",
      "\n",
      "218 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01002869  0.05223488 -0.00159583 -0.07447941]\n",
      "reward =  1.0\n",
      "totalReward =  218.0\n",
      "done =  False\n",
      "\n",
      "219 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01107339 -0.14286415 -0.00308542  0.2176996 ]\n",
      "reward =  1.0\n",
      "totalReward =  219.0\n",
      "done =  False\n",
      "\n",
      "220 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00821611  0.05230177  0.00126857 -0.075955  ]\n",
      "reward =  1.0\n",
      "totalReward =  220.0\n",
      "done =  False\n",
      "\n",
      "221 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00926214 -0.14283834 -0.00025053  0.21712789]\n",
      "reward =  1.0\n",
      "totalReward =  221.0\n",
      "done =  False\n",
      "\n",
      "222 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00640538  0.05228719  0.00409203 -0.07563405]\n",
      "reward =  1.0\n",
      "totalReward =  222.0\n",
      "done =  False\n",
      "\n",
      "223 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00745112  0.24735023  0.00257935 -0.3670231 ]\n",
      "reward =  1.0\n",
      "totalReward =  223.0\n",
      "done =  False\n",
      "\n",
      "224 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01239812  0.05219173 -0.00476112 -0.07352801]\n",
      "reward =  1.0\n",
      "totalReward =  224.0\n",
      "done =  False\n",
      "\n",
      "225 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01344196 -0.14286165 -0.00623168  0.21764897]\n",
      "reward =  1.0\n",
      "totalReward =  225.0\n",
      "done =  False\n",
      "\n",
      "226 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01058473  0.05234883 -0.0018787  -0.07699316]\n",
      "reward =  1.0\n",
      "totalReward =  226.0\n",
      "done =  False\n",
      "\n",
      "227 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0116317  -0.14274614 -0.00341856  0.21509644]\n",
      "reward =  1.0\n",
      "totalReward =  227.0\n",
      "done =  False\n",
      "\n",
      "228 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00877678  0.05242452  0.00088337 -0.07866289]\n",
      "reward =  1.0\n",
      "totalReward =  228.0\n",
      "done =  False\n",
      "\n",
      "229 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00982527 -0.14271007 -0.00068989  0.21429862]\n",
      "reward =  1.0\n",
      "totalReward =  229.0\n",
      "done =  False\n",
      "\n",
      "230 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00697107  0.05242173  0.00359608 -0.07860185]\n",
      "reward =  1.0\n",
      "totalReward =  230.0\n",
      "done =  False\n",
      "\n",
      "231 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0080195   0.24749194  0.00202405 -0.37014803]\n",
      "reward =  1.0\n",
      "totalReward =  231.0\n",
      "done =  False\n",
      "\n",
      "232 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01296934  0.05234129 -0.00537891 -0.07682759]\n",
      "reward =  1.0\n",
      "totalReward =  232.0\n",
      "done =  False\n",
      "\n",
      "233 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01401617 -0.14270313 -0.00691546  0.21415342]\n",
      "reward =  1.0\n",
      "totalReward =  233.0\n",
      "done =  False\n",
      "\n",
      "234 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01116211  0.052517   -0.0026324  -0.0807029 ]\n",
      "reward =  1.0\n",
      "totalReward =  234.0\n",
      "done =  False\n",
      "\n",
      "235 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01221245 -0.14256711 -0.00424645  0.21114834]\n",
      "reward =  1.0\n",
      "totalReward =  235.0\n",
      "done =  False\n",
      "\n",
      "236 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 9.3611032e-03  5.2615289e-02 -2.3487661e-05 -8.2871094e-02]\n",
      "reward =  1.0\n",
      "totalReward =  236.0\n",
      "done =  False\n",
      "\n",
      "237 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01041341 -0.14250633 -0.00168091  0.20980443]\n",
      "reward =  1.0\n",
      "totalReward =  237.0\n",
      "done =  False\n",
      "\n",
      "238 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00756328  0.05263962  0.00251518 -0.08340827]\n",
      "reward =  1.0\n",
      "totalReward =  238.0\n",
      "done =  False\n",
      "\n",
      "239 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00861607 -0.1425183   0.00084701  0.21006714]\n",
      "reward =  1.0\n",
      "totalReward =  239.0\n",
      "done =  False\n",
      "\n",
      "240 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00576571  0.05259153  0.00504836 -0.08234847]\n",
      "reward =  1.0\n",
      "totalReward =  240.0\n",
      "done =  False\n",
      "\n",
      "241 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00681754 -0.14260241  0.00340139  0.21192293]\n",
      "reward =  1.0\n",
      "totalReward =  241.0\n",
      "done =  False\n",
      "\n",
      "242 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00396549  0.05247074  0.00763985 -0.0796851 ]\n",
      "reward =  1.0\n",
      "totalReward =  242.0\n",
      "done =  False\n",
      "\n",
      "243 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00501491  0.24748234  0.00604614 -0.36994788]\n",
      "reward =  1.0\n",
      "totalReward =  243.0\n",
      "done =  False\n",
      "\n",
      "244 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00996455  0.05227501 -0.00135281 -0.07536468]\n",
      "reward =  1.0\n",
      "totalReward =  244.0\n",
      "done =  False\n",
      "\n",
      "245 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01101005 -0.14282753 -0.00286011  0.21689112]\n",
      "reward =  1.0\n",
      "totalReward =  245.0\n",
      "done =  False\n",
      "\n",
      "246 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0081535   0.0523352   0.00147772 -0.07669263]\n",
      "reward =  1.0\n",
      "totalReward =  246.0\n",
      "done =  False\n",
      "\n",
      "247 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 9.2002060e-03 -1.4280790e-01 -5.6137411e-05  2.1645616e-01]\n",
      "reward =  1.0\n",
      "totalReward =  247.0\n",
      "done =  False\n",
      "\n",
      "248 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00634405  0.05231485  0.00427299 -0.07624448]\n",
      "reward =  1.0\n",
      "totalReward =  248.0\n",
      "done =  False\n",
      "\n",
      "249 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00739034  0.24737528  0.0027481  -0.3675762 ]\n",
      "reward =  1.0\n",
      "totalReward =  249.0\n",
      "done =  False\n",
      "\n",
      "250 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01233785  0.05221439 -0.00460343 -0.07402803]\n",
      "reward =  1.0\n",
      "totalReward =  250.0\n",
      "done =  False\n",
      "\n",
      "251 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01338214 -0.14284126 -0.00608399  0.21719894]\n",
      "reward =  1.0\n",
      "totalReward =  251.0\n",
      "done =  False\n",
      "\n",
      "252 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01052531  0.05236713 -0.00174001 -0.07739691]\n",
      "reward =  1.0\n",
      "totalReward =  252.0\n",
      "done =  False\n",
      "\n",
      "253 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01157266 -0.14272983 -0.00328795  0.21473654]\n",
      "reward =  1.0\n",
      "totalReward =  253.0\n",
      "done =  False\n",
      "\n",
      "254 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00871806  0.05243897  0.00100678 -0.07898174]\n",
      "reward =  1.0\n",
      "totalReward =  254.0\n",
      "done =  False\n",
      "\n",
      "255 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00976684 -0.1426974  -0.00057285  0.21401866]\n",
      "reward =  1.0\n",
      "totalReward =  255.0\n",
      "done =  False\n",
      "\n",
      "256 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00691289  0.05243273  0.00370752 -0.07884492]\n",
      "reward =  1.0\n",
      "totalReward =  256.0\n",
      "done =  False\n",
      "\n",
      "257 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00796155  0.24750134  0.00213062 -0.3703558 ]\n",
      "reward =  1.0\n",
      "totalReward =  257.0\n",
      "done =  False\n",
      "\n",
      "258 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01291157  0.05234918 -0.00527649 -0.07700183]\n",
      "reward =  1.0\n",
      "totalReward =  258.0\n",
      "done =  False\n",
      "\n",
      "259 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01395856 -0.14269672 -0.00681653  0.21401168]\n",
      "reward =  1.0\n",
      "totalReward =  259.0\n",
      "done =  False\n",
      "\n",
      "260 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01110462  0.05252201 -0.0025363  -0.08081367]\n",
      "reward =  1.0\n",
      "totalReward =  260.0\n",
      "done =  False\n",
      "\n",
      "261 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01215506 -0.14256349 -0.00415257  0.21106797]\n",
      "reward =  1.0\n",
      "totalReward =  261.0\n",
      "done =  False\n",
      "\n",
      "262 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 9.3037914e-03  5.2617587e-02  6.8789312e-05 -8.2921974e-02]\n",
      "reward =  1.0\n",
      "totalReward =  262.0\n",
      "done =  False\n",
      "\n",
      "263 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01035614 -0.14250535 -0.00158965  0.20978266]\n",
      "reward =  1.0\n",
      "totalReward =  263.0\n",
      "done =  False\n",
      "\n",
      "264 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00750604  0.05263929  0.002606   -0.0834013 ]\n",
      "reward =  1.0\n",
      "totalReward =  264.0\n",
      "done =  False\n",
      "\n",
      "265 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00855882 -0.14251992  0.00093798  0.21010269]\n",
      "reward =  1.0\n",
      "totalReward =  265.0\n",
      "done =  False\n",
      "\n",
      "266 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00570842  0.05258861  0.00514003 -0.08228421]\n",
      "reward =  1.0\n",
      "totalReward =  266.0\n",
      "done =  False\n",
      "\n",
      "267 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0067602  -0.14260665  0.00349435  0.21201597]\n",
      "reward =  1.0\n",
      "totalReward =  267.0\n",
      "done =  False\n",
      "\n",
      "268 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00390806  0.05246517  0.00773467 -0.07956263]\n",
      "reward =  1.0\n",
      "totalReward =  268.0\n",
      "done =  False\n",
      "\n",
      "269 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00495737  0.2474754   0.00614341 -0.36979526]\n",
      "reward =  1.0\n",
      "totalReward =  269.0\n",
      "done =  False\n",
      "\n",
      "270 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00990687  0.0522667  -0.00125249 -0.07518158]\n",
      "reward =  1.0\n",
      "totalReward =  270.0\n",
      "done =  False\n",
      "\n",
      "271 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01095221 -0.14283727 -0.00275612  0.21710591]\n",
      "reward =  1.0\n",
      "totalReward =  271.0\n",
      "done =  False\n",
      "\n",
      "272 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00809546  0.05232397  0.00158599 -0.07644514]\n",
      "reward =  1.0\n",
      "totalReward =  272.0\n",
      "done =  False\n",
      "\n",
      "273 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 9.1419425e-03 -1.4282069e-01  5.7091955e-05  2.1673776e-01]\n",
      "reward =  1.0\n",
      "totalReward =  273.0\n",
      "done =  False\n",
      "\n",
      "274 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00628553  0.05230045  0.00439185 -0.07592716]\n",
      "reward =  1.0\n",
      "totalReward =  274.0\n",
      "done =  False\n",
      "\n",
      "275 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00733154  0.24735917  0.0028733  -0.3672212 ]\n",
      "reward =  1.0\n",
      "totalReward =  275.0\n",
      "done =  False\n",
      "\n",
      "276 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01227872  0.05219651 -0.00447112 -0.07363368]\n",
      "reward =  1.0\n",
      "totalReward =  276.0\n",
      "done =  False\n",
      "\n",
      "277 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01332265 -0.14286107 -0.00594379  0.21763524]\n",
      "reward =  1.0\n",
      "totalReward =  277.0\n",
      "done =  False\n",
      "\n",
      "278 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01046543  0.05234535 -0.00159109 -0.07691667]\n",
      "reward =  1.0\n",
      "totalReward =  278.0\n",
      "done =  False\n",
      "\n",
      "279 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01151234 -0.14275375 -0.00312942  0.21526384]\n",
      "reward =  1.0\n",
      "totalReward =  279.0\n",
      "done =  False\n",
      "\n",
      "280 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00865726  0.0524128   0.00117585 -0.0784046 ]\n",
      "reward =  1.0\n",
      "totalReward =  280.0\n",
      "done =  False\n",
      "\n",
      "281 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00970552 -0.14272599 -0.00039224  0.21464908]\n",
      "reward =  1.0\n",
      "totalReward =  281.0\n",
      "done =  False\n",
      "\n",
      "282 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.006851    0.05240157  0.00390074 -0.07815755]\n",
      "reward =  1.0\n",
      "totalReward =  282.0\n",
      "done =  False\n",
      "\n",
      "283 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00789903  0.24746738  0.00233759 -0.36960724]\n",
      "reward =  1.0\n",
      "totalReward =  283.0\n",
      "done =  False\n",
      "\n",
      "284 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01284838  0.0523123  -0.00505455 -0.07618815]\n",
      "reward =  1.0\n",
      "totalReward =  284.0\n",
      "done =  False\n",
      "\n",
      "285 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01389462 -0.14273684 -0.00657832  0.21489577]\n",
      "reward =  1.0\n",
      "totalReward =  285.0\n",
      "done =  False\n",
      "\n",
      "286 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01103989  0.05247854 -0.0022804  -0.07985497]\n",
      "reward =  1.0\n",
      "totalReward =  286.0\n",
      "done =  False\n",
      "\n",
      "287 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01208946 -0.14261064 -0.0038775   0.21210761]\n",
      "reward =  1.0\n",
      "totalReward =  287.0\n",
      "done =  False\n",
      "\n",
      "288 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00923724  0.05256653  0.00036465 -0.08179593]\n",
      "reward =  1.0\n",
      "totalReward =  288.0\n",
      "done =  False\n",
      "\n",
      "289 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01028857 -0.14256065 -0.00127127  0.21100202]\n",
      "reward =  1.0\n",
      "totalReward =  289.0\n",
      "done =  False\n",
      "\n",
      "290 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00743736  0.05257946  0.00294878 -0.08208165]\n",
      "reward =  1.0\n",
      "totalReward =  290.0\n",
      "done =  False\n",
      "\n",
      "291 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00848895 -0.14258464  0.00130714  0.21153016]\n",
      "reward =  1.0\n",
      "totalReward =  291.0\n",
      "done =  False\n",
      "\n",
      "292 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00563726  0.0525186   0.00553775 -0.08074015]\n",
      "reward =  1.0\n",
      "totalReward =  292.0\n",
      "done =  False\n",
      "\n",
      "293 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00668763  0.24756072  0.00392294 -0.37167075]\n",
      "reward =  1.0\n",
      "totalReward =  293.0\n",
      "done =  False\n",
      "\n",
      "294 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01163885  0.05238327 -0.00351047 -0.07775348]\n",
      "reward =  1.0\n",
      "totalReward =  294.0\n",
      "done =  False\n",
      "\n",
      "295 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01268651 -0.14268818 -0.00506554  0.21381982]\n",
      "reward =  1.0\n",
      "totalReward =  295.0\n",
      "done =  False\n",
      "\n",
      "296 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00983275  0.05250582 -0.00078915 -0.0804567 ]\n",
      "reward =  1.0\n",
      "totalReward =  296.0\n",
      "done =  False\n",
      "\n",
      "297 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01088286 -0.14260481 -0.00239828  0.21197714]\n",
      "reward =  1.0\n",
      "totalReward =  297.0\n",
      "done =  False\n",
      "\n",
      "298 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00803077  0.05255135  0.00184126 -0.08146135]\n",
      "reward =  1.0\n",
      "totalReward =  298.0\n",
      "done =  False\n",
      "\n",
      "299 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00908179 -0.14259695  0.00021204  0.21180193]\n",
      "reward =  1.0\n",
      "totalReward =  299.0\n",
      "done =  False\n",
      "\n",
      "300 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00622986  0.05252197  0.00444807 -0.0808141 ]\n",
      "reward =  1.0\n",
      "totalReward =  300.0\n",
      "done =  False\n",
      "\n",
      "301 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00728029 -0.14266346  0.00283179  0.21326888]\n",
      "reward =  1.0\n",
      "totalReward =  301.0\n",
      "done =  False\n",
      "\n",
      "302 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00442703  0.05241789  0.00709717 -0.07851943]\n",
      "reward =  1.0\n",
      "totalReward =  302.0\n",
      "done =  False\n",
      "\n",
      "303 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00547538  0.24743739  0.00552678 -0.36895475]\n",
      "reward =  1.0\n",
      "totalReward =  303.0\n",
      "done =  False\n",
      "\n",
      "304 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01042413  0.05223735 -0.00185231 -0.07453429]\n",
      "reward =  1.0\n",
      "totalReward =  304.0\n",
      "done =  False\n",
      "\n",
      "305 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01146888 -0.142858   -0.003343    0.21756364]\n",
      "reward =  1.0\n",
      "totalReward =  305.0\n",
      "done =  False\n",
      "\n",
      "306 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00861172  0.05231158  0.00100827 -0.07617193]\n",
      "reward =  1.0\n",
      "totalReward =  306.0\n",
      "done =  False\n",
      "\n",
      "307 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00965795 -0.14282481 -0.00051516  0.21682894]\n",
      "reward =  1.0\n",
      "totalReward =  307.0\n",
      "done =  False\n",
      "\n",
      "308 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00680145  0.0523045   0.00382141 -0.07601645]\n",
      "reward =  1.0\n",
      "totalReward =  308.0\n",
      "done =  False\n",
      "\n",
      "309 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00784754  0.24737146  0.00230109 -0.36749125]\n",
      "reward =  1.0\n",
      "totalReward =  309.0\n",
      "done =  False\n",
      "\n",
      "310 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01279497  0.05221689 -0.00504874 -0.07408366]\n",
      "reward =  1.0\n",
      "totalReward =  310.0\n",
      "done =  False\n",
      "\n",
      "311 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01383931 -0.14283232 -0.00653041  0.21700211]\n",
      "reward =  1.0\n",
      "totalReward =  311.0\n",
      "done =  False\n",
      "\n",
      "312 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01098266  0.05238237 -0.00219037 -0.07773362]\n",
      "reward =  1.0\n",
      "totalReward =  312.0\n",
      "done =  False\n",
      "\n",
      "313 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01203031 -0.14270811 -0.00374504  0.21425743]\n",
      "reward =  1.0\n",
      "totalReward =  313.0\n",
      "done =  False\n",
      "\n",
      "314 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00917615  0.05246718  0.00054011 -0.07960449]\n",
      "reward =  1.0\n",
      "totalReward =  314.0\n",
      "done =  False\n",
      "\n",
      "315 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01022549 -0.14266251 -0.00105198  0.21324879]\n",
      "reward =  1.0\n",
      "totalReward =  315.0\n",
      "done =  False\n",
      "\n",
      "316 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00737224  0.05247447  0.00321299 -0.07976579]\n",
      "reward =  1.0\n",
      "totalReward =  316.0\n",
      "done =  False\n",
      "\n",
      "317 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00842173 -0.1426934   0.00161768  0.2139291 ]\n",
      "reward =  1.0\n",
      "totalReward =  317.0\n",
      "done =  False\n",
      "\n",
      "318 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00556786  0.05240539  0.00589626 -0.07824309]\n",
      "reward =  1.0\n",
      "totalReward =  318.0\n",
      "done =  False\n",
      "\n",
      "319 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00661597  0.24744232  0.0043314  -0.36905992]\n",
      "reward =  1.0\n",
      "totalReward =  319.0\n",
      "done =  False\n",
      "\n",
      "320 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01156482  0.0522591  -0.0030498  -0.0750144 ]\n",
      "reward =  1.0\n",
      "totalReward =  320.0\n",
      "done =  False\n",
      "\n",
      "321 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01261    -0.142819   -0.00455009  0.21670476]\n",
      "reward =  1.0\n",
      "totalReward =  321.0\n",
      "done =  False\n",
      "\n",
      "322 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00975362  0.0523677  -0.000216   -0.07740999]\n",
      "reward =  1.0\n",
      "totalReward =  322.0\n",
      "done =  False\n",
      "\n",
      "323 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01080097 -0.14275116 -0.0017642   0.21520478]\n",
      "reward =  1.0\n",
      "totalReward =  323.0\n",
      "done =  False\n",
      "\n",
      "324 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00794595  0.05239597  0.0025399  -0.07803413]\n",
      "reward =  1.0\n",
      "totalReward =  324.0\n",
      "done =  False\n",
      "\n",
      "325 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00899387 -0.14276229  0.00097922  0.21544906]\n",
      "reward =  1.0\n",
      "totalReward =  325.0\n",
      "done =  False\n",
      "\n",
      "326 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00613862  0.05234564  0.0052882  -0.07692482]\n",
      "reward =  1.0\n",
      "totalReward =  326.0\n",
      "done =  False\n",
      "\n",
      "327 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00718554  0.24739139  0.0037497  -0.3679346 ]\n",
      "reward =  1.0\n",
      "totalReward =  327.0\n",
      "done =  False\n",
      "\n",
      "328 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01213337  0.05221635 -0.00360899 -0.07407172]\n",
      "reward =  1.0\n",
      "totalReward =  328.0\n",
      "done =  False\n",
      "\n",
      "329 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01317769 -0.14285368 -0.00509042  0.21747038]\n",
      "reward =  1.0\n",
      "totalReward =  329.0\n",
      "done =  False\n",
      "\n",
      "330 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01032062  0.05234068 -0.00074102 -0.07681394]\n",
      "reward =  1.0\n",
      "totalReward =  330.0\n",
      "done =  False\n",
      "\n",
      "331 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01136743 -0.14277065 -0.0022773   0.2156351 ]\n",
      "reward =  1.0\n",
      "totalReward =  331.0\n",
      "done =  False\n",
      "\n",
      "332 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00851202  0.05238379  0.00203541 -0.07776531]\n",
      "reward =  1.0\n",
      "totalReward =  332.0\n",
      "done =  False\n",
      "\n",
      "333 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0095597  -0.14276728  0.0004801   0.2155591 ]\n",
      "reward =  1.0\n",
      "totalReward =  333.0\n",
      "done =  False\n",
      "\n",
      "334 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00670435  0.05234781  0.00479128 -0.07697234]\n",
      "reward =  1.0\n",
      "totalReward =  334.0\n",
      "done =  False\n",
      "\n",
      "335 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00775131  0.24740075  0.00325184 -0.36813977]\n",
      "reward =  1.0\n",
      "totalReward =  335.0\n",
      "done =  False\n",
      "\n",
      "336 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01269932  0.05223274 -0.00411096 -0.07443326]\n",
      "reward =  1.0\n",
      "totalReward =  336.0\n",
      "done =  False\n",
      "\n",
      "337 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01374398 -0.14283004 -0.00559962  0.2169498 ]\n",
      "reward =  1.0\n",
      "totalReward =  337.0\n",
      "done =  False\n",
      "\n",
      "338 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01088738  0.05237151 -0.00126063 -0.07749421]\n",
      "reward =  1.0\n",
      "totalReward =  338.0\n",
      "done =  False\n",
      "\n",
      "339 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0119348  -0.14273234 -0.00281051  0.21479072]\n",
      "reward =  1.0\n",
      "totalReward =  339.0\n",
      "done =  False\n",
      "\n",
      "340 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00908016  0.05242968  0.0014853  -0.07877744]\n",
      "reward =  1.0\n",
      "totalReward =  340.0\n",
      "done =  False\n",
      "\n",
      "341 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 1.0128751e-02 -1.4271353e-01 -9.0247202e-05  2.1437374e-01]\n",
      "reward =  1.0\n",
      "totalReward =  341.0\n",
      "done =  False\n",
      "\n",
      "342 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00727448  0.0524097   0.00419723 -0.07833766]\n",
      "reward =  1.0\n",
      "totalReward =  342.0\n",
      "done =  False\n",
      "\n",
      "343 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00832267  0.24747124  0.00263047 -0.3696934 ]\n",
      "reward =  1.0\n",
      "totalReward =  343.0\n",
      "done =  False\n",
      "\n",
      "344 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0132721   0.05231201 -0.00476339 -0.07618222]\n",
      "reward =  1.0\n",
      "totalReward =  344.0\n",
      "done =  False\n",
      "\n",
      "345 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01431834 -0.14274134 -0.00628704  0.21499404]\n",
      "reward =  1.0\n",
      "totalReward =  345.0\n",
      "done =  False\n",
      "\n",
      "346 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01146351  0.05246994 -0.00198716 -0.07966544]\n",
      "reward =  1.0\n",
      "totalReward =  346.0\n",
      "done =  False\n",
      "\n",
      "347 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01251291 -0.14262347 -0.00358047  0.21238987]\n",
      "reward =  1.0\n",
      "totalReward =  347.0\n",
      "done =  False\n",
      "\n",
      "348 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00966044  0.05254949  0.00066733 -0.08142035]\n",
      "reward =  1.0\n",
      "totalReward =  348.0\n",
      "done =  False\n",
      "\n",
      "349 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01071143 -0.14258203 -0.00096108  0.21147305]\n",
      "reward =  1.0\n",
      "totalReward =  349.0\n",
      "done =  False\n",
      "\n",
      "350 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00785979  0.05255365  0.00326839 -0.08151289]\n",
      "reward =  1.0\n",
      "totalReward =  350.0\n",
      "done =  False\n",
      "\n",
      "351 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00891086 -0.14261499  0.00163813  0.21219942]\n",
      "reward =  1.0\n",
      "totalReward =  351.0\n",
      "done =  False\n",
      "\n",
      "352 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00605856  0.0524835   0.00588212 -0.07996631]\n",
      "reward =  1.0\n",
      "totalReward =  352.0\n",
      "done =  False\n",
      "\n",
      "353 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00710823  0.24752063  0.00428279 -0.37078762]\n",
      "reward =  1.0\n",
      "totalReward =  353.0\n",
      "done =  False\n",
      "\n",
      "354 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01205865  0.0523381  -0.00313296 -0.07675737]\n",
      "reward =  1.0\n",
      "totalReward =  354.0\n",
      "done =  False\n",
      "\n",
      "355 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01310541 -0.1427388  -0.00466811  0.21493545]\n",
      "reward =  1.0\n",
      "totalReward =  355.0\n",
      "done =  False\n",
      "\n",
      "356 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01025063  0.05244958 -0.0003694  -0.07921635]\n",
      "reward =  1.0\n",
      "totalReward =  356.0\n",
      "done =  False\n",
      "\n",
      "357 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01129963 -0.14266708 -0.00195373  0.21335001]\n",
      "reward =  1.0\n",
      "totalReward =  357.0\n",
      "done =  False\n",
      "\n",
      "358 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00844628  0.05248275  0.00231327 -0.07994857]\n",
      "reward =  1.0\n",
      "totalReward =  358.0\n",
      "done =  False\n",
      "\n",
      "359 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00949594 -0.14267229  0.0007143   0.2134633 ]\n",
      "reward =  1.0\n",
      "totalReward =  359.0\n",
      "done =  False\n",
      "\n",
      "360 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00664249  0.05243945  0.00498357 -0.07899421]\n",
      "reward =  1.0\n",
      "totalReward =  360.0\n",
      "done =  False\n",
      "\n",
      "361 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00769128  0.2474896   0.00340368 -0.37010065]\n",
      "reward =  1.0\n",
      "totalReward =  361.0\n",
      "done =  False\n",
      "\n",
      "362 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01264107  0.05231946 -0.00399833 -0.07634645]\n",
      "reward =  1.0\n",
      "totalReward =  362.0\n",
      "done =  False\n",
      "\n",
      "363 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01368746 -0.14274494 -0.00552526  0.2150723 ]\n",
      "reward =  1.0\n",
      "totalReward =  363.0\n",
      "done =  False\n",
      "\n",
      "364 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01083256  0.05245556 -0.00122381 -0.07934839]\n",
      "reward =  1.0\n",
      "totalReward =  364.0\n",
      "done =  False\n",
      "\n",
      "365 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01188167 -0.14264883 -0.00281078  0.21294816]\n",
      "reward =  1.0\n",
      "totalReward =  365.0\n",
      "done =  False\n",
      "\n",
      "366 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0090287   0.0525132   0.00144818 -0.08062009]\n",
      "reward =  1.0\n",
      "totalReward =  366.0\n",
      "done =  False\n",
      "\n",
      "367 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 1.0078962e-02 -1.4262949e-01 -1.6421940e-04  2.1251939e-01]\n",
      "reward =  1.0\n",
      "totalReward =  367.0\n",
      "done =  False\n",
      "\n",
      "368 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00722637  0.05249481  0.00408617 -0.08021533]\n",
      "reward =  1.0\n",
      "totalReward =  368.0\n",
      "done =  False\n",
      "\n",
      "369 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00827627  0.24755795  0.00248186 -0.37160626]\n",
      "reward =  1.0\n",
      "totalReward =  369.0\n",
      "done =  False\n",
      "\n",
      "370 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01322743  0.05240083 -0.00495026 -0.07814182]\n",
      "reward =  1.0\n",
      "totalReward =  370.0\n",
      "done =  False\n",
      "\n",
      "371 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01427544 -0.14264981 -0.0065131   0.21297519]\n",
      "reward =  1.0\n",
      "totalReward =  371.0\n",
      "done =  False\n",
      "\n",
      "372 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01142245  0.05256465 -0.0022536  -0.08175513]\n",
      "reward =  1.0\n",
      "totalReward =  372.0\n",
      "done =  False\n",
      "\n",
      "373 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01247374 -0.14252491 -0.0038887   0.21021593]\n",
      "reward =  1.0\n",
      "totalReward =  373.0\n",
      "done =  False\n",
      "\n",
      "374 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00962324  0.05265241  0.00031562 -0.08369114]\n",
      "reward =  1.0\n",
      "totalReward =  374.0\n",
      "done =  False\n",
      "\n",
      "375 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01067629 -0.14247406 -0.0013582   0.20909135]\n",
      "reward =  1.0\n",
      "totalReward =  375.0\n",
      "done =  False\n",
      "\n",
      "376 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00782681  0.05266729  0.00282362 -0.08401971]\n",
      "reward =  1.0\n",
      "totalReward =  376.0\n",
      "done =  False\n",
      "\n",
      "377 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00888016 -0.14249502  0.00114323  0.20955274]\n",
      "reward =  1.0\n",
      "totalReward =  377.0\n",
      "done =  False\n",
      "\n",
      "378 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00603026  0.05261056  0.00533429 -0.08276934]\n",
      "reward =  1.0\n",
      "totalReward =  378.0\n",
      "done =  False\n",
      "\n",
      "379 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00708247 -0.14258745  0.0036789   0.21159178]\n",
      "reward =  1.0\n",
      "totalReward =  379.0\n",
      "done =  False\n",
      "\n",
      "380 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00423072  0.05248171  0.00791073 -0.07992838]\n",
      "reward =  1.0\n",
      "totalReward =  380.0\n",
      "done =  False\n",
      "\n",
      "381 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00528035  0.24748938  0.00631217 -0.370105  ]\n",
      "reward =  1.0\n",
      "totalReward =  381.0\n",
      "done =  False\n",
      "\n",
      "382 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01023014  0.05227831 -0.00108993 -0.07543847]\n",
      "reward =  1.0\n",
      "totalReward =  382.0\n",
      "done =  False\n",
      "\n",
      "383 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01127571 -0.142828   -0.0025987   0.21690038]\n",
      "reward =  1.0\n",
      "totalReward =  383.0\n",
      "done =  False\n",
      "\n",
      "384 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00841915  0.052331    0.0017393  -0.07660116]\n",
      "reward =  1.0\n",
      "totalReward =  384.0\n",
      "done =  False\n",
      "\n",
      "385 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 9.4657652e-03 -1.4281584e-01  2.0728144e-04  2.1663003e-01]\n",
      "reward =  1.0\n",
      "totalReward =  385.0\n",
      "done =  False\n",
      "\n",
      "386 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00660945  0.05230315  0.00453988 -0.07598751]\n",
      "reward =  1.0\n",
      "totalReward =  386.0\n",
      "done =  False\n",
      "\n",
      "387 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00765551  0.24735972  0.00302013 -0.36723465]\n",
      "reward =  1.0\n",
      "totalReward =  387.0\n",
      "done =  False\n",
      "\n",
      "388 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01260271  0.05219499 -0.00432456 -0.07360096]\n",
      "reward =  1.0\n",
      "totalReward =  388.0\n",
      "done =  False\n",
      "\n",
      "389 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01364661 -0.1428647  -0.00579658  0.21771443]\n",
      "reward =  1.0\n",
      "totalReward =  389.0\n",
      "done =  False\n",
      "\n",
      "390 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01078931  0.05233964 -0.00144229 -0.07679134]\n",
      "reward =  1.0\n",
      "totalReward =  390.0\n",
      "done =  False\n",
      "\n",
      "391 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01183611 -0.14276162 -0.00297812  0.21543619]\n",
      "reward =  1.0\n",
      "totalReward =  391.0\n",
      "done =  False\n",
      "\n",
      "392 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00898087  0.05240279  0.00133061 -0.07818468]\n",
      "reward =  1.0\n",
      "totalReward =  392.0\n",
      "done =  False\n",
      "\n",
      "393 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01002893 -0.14273821 -0.00023309  0.21491776]\n",
      "reward =  1.0\n",
      "totalReward =  393.0\n",
      "done =  False\n",
      "\n",
      "394 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00717416  0.05238707  0.00406527 -0.07783868]\n",
      "reward =  1.0\n",
      "totalReward =  394.0\n",
      "done =  False\n",
      "\n",
      "395 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00822191  0.24745052  0.00250849 -0.36923623]\n",
      "reward =  1.0\n",
      "totalReward =  395.0\n",
      "done =  False\n",
      "\n",
      "396 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01317092  0.05229301 -0.00487623 -0.0757634 ]\n",
      "reward =  1.0\n",
      "totalReward =  396.0\n",
      "done =  False\n",
      "\n",
      "397 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01421678 -0.1427587  -0.0063915   0.21537708]\n",
      "reward =  1.0\n",
      "totalReward =  397.0\n",
      "done =  False\n",
      "\n",
      "398 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0113616   0.05245404 -0.00208396 -0.07931514]\n",
      "reward =  1.0\n",
      "totalReward =  398.0\n",
      "done =  False\n",
      "\n",
      "399 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01241068 -0.14263798 -0.00367026  0.21270956]\n",
      "reward =  1.0\n",
      "totalReward =  399.0\n",
      "done =  False\n",
      "\n",
      "400 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00955792  0.05253626  0.00058393 -0.08112887]\n",
      "reward =  1.0\n",
      "totalReward =  400.0\n",
      "done =  False\n",
      "\n",
      "401 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01060865 -0.14259405 -0.00103865  0.21173823]\n",
      "reward =  1.0\n",
      "totalReward =  401.0\n",
      "done =  False\n",
      "\n",
      "402 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00775677  0.05254272  0.00319612 -0.08127216]\n",
      "reward =  1.0\n",
      "totalReward =  402.0\n",
      "done =  False\n",
      "\n",
      "403 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00880762 -0.1426249   0.00157067  0.21241744]\n",
      "reward =  1.0\n",
      "totalReward =  403.0\n",
      "done =  False\n",
      "\n",
      "404 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00595512  0.05247456  0.00581902 -0.07976961]\n",
      "reward =  1.0\n",
      "totalReward =  404.0\n",
      "done =  False\n",
      "\n",
      "405 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00700461  0.24751261  0.00422363 -0.37061095]\n",
      "reward =  1.0\n",
      "totalReward =  405.0\n",
      "done =  False\n",
      "\n",
      "406 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01195487  0.05233091 -0.00318859 -0.07659927]\n",
      "reward =  1.0\n",
      "totalReward =  406.0\n",
      "done =  False\n",
      "\n",
      "407 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01300148 -0.14274518 -0.00472057  0.21507594]\n",
      "reward =  1.0\n",
      "totalReward =  407.0\n",
      "done =  False\n",
      "\n",
      "408 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01014658  0.05244394 -0.00041905 -0.07909232]\n",
      "reward =  1.0\n",
      "totalReward =  408.0\n",
      "done =  False\n",
      "\n",
      "409 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01119546 -0.142672   -0.0020009   0.21345837]\n",
      "reward =  1.0\n",
      "totalReward =  409.0\n",
      "done =  False\n",
      "\n",
      "410 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00834202  0.0524785   0.00226827 -0.07985506]\n",
      "reward =  1.0\n",
      "totalReward =  410.0\n",
      "done =  False\n",
      "\n",
      "411 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00939159 -0.14267589  0.00067117  0.21354266]\n",
      "reward =  1.0\n",
      "totalReward =  411.0\n",
      "done =  False\n",
      "\n",
      "412 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00653807  0.05243645  0.00494202 -0.07892849]\n",
      "reward =  1.0\n",
      "totalReward =  412.0\n",
      "done =  False\n",
      "\n",
      "413 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0075868   0.2474872   0.00336345 -0.3700481 ]\n",
      "reward =  1.0\n",
      "totalReward =  413.0\n",
      "done =  False\n",
      "\n",
      "414 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01253655  0.05231763 -0.00403751 -0.07630654]\n",
      "reward =  1.0\n",
      "totalReward =  414.0\n",
      "done =  False\n",
      "\n",
      "415 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0135829  -0.14274621 -0.00556364  0.21509981]\n",
      "reward =  1.0\n",
      "totalReward =  415.0\n",
      "done =  False\n",
      "\n",
      "416 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01072797  0.05245484 -0.00126165 -0.07933293]\n",
      "reward =  1.0\n",
      "totalReward =  416.0\n",
      "done =  False\n",
      "\n",
      "417 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01177707 -0.142649   -0.00284831  0.21295168]\n",
      "reward =  1.0\n",
      "totalReward =  417.0\n",
      "done =  False\n",
      "\n",
      "418 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00892409  0.05251355  0.00141073 -0.08062838]\n",
      "reward =  1.0\n",
      "totalReward =  418.0\n",
      "done =  False\n",
      "\n",
      "419 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 9.9743614e-03 -1.4262860e-01 -2.0184084e-04  2.1249931e-01]\n",
      "reward =  1.0\n",
      "totalReward =  419.0\n",
      "done =  False\n",
      "\n",
      "420 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00712179  0.05249625  0.00404815 -0.08024729]\n",
      "reward =  1.0\n",
      "totalReward =  420.0\n",
      "done =  False\n",
      "\n",
      "421 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00817171  0.24755993  0.0024432  -0.37165028]\n",
      "reward =  1.0\n",
      "totalReward =  421.0\n",
      "done =  False\n",
      "\n",
      "422 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01312291  0.05240336 -0.00498981 -0.07819798]\n",
      "reward =  1.0\n",
      "totalReward =  422.0\n",
      "done =  False\n",
      "\n",
      "423 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01417098 -0.1426467  -0.00655377  0.21290648]\n",
      "reward =  1.0\n",
      "totalReward =  423.0\n",
      "done =  False\n",
      "\n",
      "424 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01131805  0.05256833 -0.00229564 -0.08183658]\n",
      "reward =  1.0\n",
      "totalReward =  424.0\n",
      "done =  False\n",
      "\n",
      "425 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01236941 -0.14252064 -0.00393237  0.21012118]\n",
      "reward =  1.0\n",
      "totalReward =  425.0\n",
      "done =  False\n",
      "\n",
      "426 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.009519    0.05265732  0.00027006 -0.0837996 ]\n",
      "reward =  1.0\n",
      "totalReward =  426.0\n",
      "done =  False\n",
      "\n",
      "427 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01057215 -0.14246851 -0.00140594  0.20896852]\n",
      "reward =  1.0\n",
      "totalReward =  427.0\n",
      "done =  False\n",
      "\n",
      "428 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00772278  0.05267352  0.00277343 -0.08415758]\n",
      "reward =  1.0\n",
      "totalReward =  428.0\n",
      "done =  False\n",
      "\n",
      "429 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00877625 -0.14248808  0.00109028  0.20939907]\n",
      "reward =  1.0\n",
      "totalReward =  429.0\n",
      "done =  False\n",
      "\n",
      "430 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00592649  0.05261827  0.00527826 -0.08293972]\n",
      "reward =  1.0\n",
      "totalReward =  430.0\n",
      "done =  False\n",
      "\n",
      "431 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00697885 -0.14257894  0.00361947  0.21140383]\n",
      "reward =  1.0\n",
      "totalReward =  431.0\n",
      "done =  False\n",
      "\n",
      "432 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00412727  0.05249107  0.00784755 -0.08013516]\n",
      "reward =  1.0\n",
      "totalReward =  432.0\n",
      "done =  False\n",
      "\n",
      "433 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00517709  0.24749964  0.00624484 -0.37033185]\n",
      "reward =  1.0\n",
      "totalReward =  433.0\n",
      "done =  False\n",
      "\n",
      "434 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01012709  0.05228953 -0.00116179 -0.07568642]\n",
      "reward =  1.0\n",
      "totalReward =  434.0\n",
      "done =  False\n",
      "\n",
      "435 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01117288 -0.14281574 -0.00267552  0.21662973]\n",
      "reward =  1.0\n",
      "totalReward =  435.0\n",
      "done =  False\n",
      "\n",
      "436 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00831656  0.05234435  0.00165707 -0.07689598]\n",
      "reward =  1.0\n",
      "totalReward =  436.0\n",
      "done =  False\n",
      "\n",
      "437 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 9.3634492e-03 -1.4280131e-01  1.1915235e-04  2.1630929e-01]\n",
      "reward =  1.0\n",
      "totalReward =  437.0\n",
      "done =  False\n",
      "\n",
      "438 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00650742  0.05231893  0.00444534 -0.07633604]\n",
      "reward =  1.0\n",
      "totalReward =  438.0\n",
      "done =  False\n",
      "\n",
      "439 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0075538   0.24737687  0.00291862 -0.36761314]\n",
      "reward =  1.0\n",
      "totalReward =  439.0\n",
      "done =  False\n",
      "\n",
      "440 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01250134  0.05221358 -0.00443365 -0.07401136]\n",
      "reward =  1.0\n",
      "totalReward =  440.0\n",
      "done =  False\n",
      "\n",
      "441 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01354561 -0.14284454 -0.00591387  0.21726944]\n",
      "reward =  1.0\n",
      "totalReward =  441.0\n",
      "done =  False\n",
      "\n",
      "442 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01068872  0.05236145 -0.00156848 -0.07727309]\n",
      "reward =  1.0\n",
      "totalReward =  442.0\n",
      "done =  False\n",
      "\n",
      "443 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01173595 -0.14273797 -0.00311395  0.21491456]\n",
      "reward =  1.0\n",
      "totalReward =  443.0\n",
      "done =  False\n",
      "\n",
      "444 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00888119  0.05242835  0.00118435 -0.07874902]\n",
      "reward =  1.0\n",
      "totalReward =  444.0\n",
      "done =  False\n",
      "\n",
      "445 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00992976 -0.14271055 -0.00039063  0.21430734]\n",
      "reward =  1.0\n",
      "totalReward =  445.0\n",
      "done =  False\n",
      "\n",
      "446 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00707555  0.05241698  0.00389551 -0.07849878]\n",
      "reward =  1.0\n",
      "totalReward =  446.0\n",
      "done =  False\n",
      "\n",
      "447 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00812388  0.24748287  0.00232554 -0.36995012]\n",
      "reward =  1.0\n",
      "totalReward =  447.0\n",
      "done =  False\n",
      "\n",
      "448 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01307354  0.05232796 -0.00507347 -0.07653484]\n",
      "reward =  1.0\n",
      "totalReward =  448.0\n",
      "done =  False\n",
      "\n",
      "449 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.0141201  -0.1427209  -0.00660416  0.21454309]\n",
      "reward =  1.0\n",
      "totalReward =  449.0\n",
      "done =  False\n",
      "\n",
      "450 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01126568  0.05249485 -0.0023133  -0.08021575]\n",
      "reward =  1.0\n",
      "totalReward =  450.0\n",
      "done =  False\n",
      "\n",
      "451 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01231558 -0.14259388 -0.00391762  0.21173643]\n",
      "reward =  1.0\n",
      "totalReward =  451.0\n",
      "done =  False\n",
      "\n",
      "452 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0094637   0.05258388  0.00031711 -0.08217972]\n",
      "reward =  1.0\n",
      "totalReward =  452.0\n",
      "done =  False\n",
      "\n",
      "453 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01051538 -0.14254262 -0.00132648  0.21060324]\n",
      "reward =  1.0\n",
      "totalReward =  453.0\n",
      "done =  False\n",
      "\n",
      "454 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00766453  0.05259827  0.00288558 -0.08249783]\n",
      "reward =  1.0\n",
      "totalReward =  454.0\n",
      "done =  False\n",
      "\n",
      "455 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00871649 -0.14256492  0.00123563  0.21109411]\n",
      "reward =  1.0\n",
      "totalReward =  455.0\n",
      "done =  False\n",
      "\n",
      "456 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0058652   0.05253934  0.00545751 -0.08119878]\n",
      "reward =  1.0\n",
      "totalReward =  456.0\n",
      "done =  False\n",
      "\n",
      "457 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00691598  0.24758263  0.00383353 -0.37215486]\n",
      "reward =  1.0\n",
      "totalReward =  457.0\n",
      "done =  False\n",
      "\n",
      "458 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01186763  0.05240643 -0.00360956 -0.07826566]\n",
      "reward =  1.0\n",
      "totalReward =  458.0\n",
      "done =  False\n",
      "\n",
      "459 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01291576 -0.14266358 -0.00517488  0.21327625]\n",
      "reward =  1.0\n",
      "totalReward =  459.0\n",
      "done =  False\n",
      "\n",
      "460 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01006249  0.05253197 -0.00090935 -0.08103456]\n",
      "reward =  1.0\n",
      "totalReward =  460.0\n",
      "done =  False\n",
      "\n",
      "461 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01111313 -0.14257693 -0.00253004  0.21136132]\n",
      "reward =  1.0\n",
      "totalReward =  461.0\n",
      "done =  False\n",
      "\n",
      "462 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00826159  0.05258109  0.00169718 -0.08211862]\n",
      "reward =  1.0\n",
      "totalReward =  462.0\n",
      "done =  False\n",
      "\n",
      "463 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 9.3132136e-03 -1.4256515e-01  5.4810655e-05  2.1109928e-01]\n",
      "reward =  1.0\n",
      "totalReward =  463.0\n",
      "done =  False\n",
      "\n",
      "464 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00646191  0.05255602  0.0042768  -0.08156635]\n",
      "reward =  1.0\n",
      "totalReward =  464.0\n",
      "done =  False\n",
      "\n",
      "465 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00751303 -0.14262697  0.00264547  0.21246284]\n",
      "reward =  1.0\n",
      "totalReward =  465.0\n",
      "done =  False\n",
      "\n",
      "466 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00466049  0.05245705  0.00689473 -0.07938441]\n",
      "reward =  1.0\n",
      "totalReward =  466.0\n",
      "done =  False\n",
      "\n",
      "467 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00570963  0.2474795   0.00530704 -0.36988407]\n",
      "reward =  1.0\n",
      "totalReward =  467.0\n",
      "done =  False\n",
      "\n",
      "468 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01065922  0.05228254 -0.00209064 -0.07553252]\n",
      "reward =  1.0\n",
      "totalReward =  468.0\n",
      "done =  False\n",
      "\n",
      "469 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01170487 -0.14280938 -0.00360129  0.21649007]\n",
      "reward =  1.0\n",
      "totalReward =  469.0\n",
      "done =  False\n",
      "\n",
      "470 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00884869  0.05236387  0.00072851 -0.07732669]\n",
      "reward =  1.0\n",
      "totalReward =  470.0\n",
      "done =  False\n",
      "\n",
      "471 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00989596 -0.14276852 -0.00081803  0.215586  ]\n",
      "reward =  1.0\n",
      "totalReward =  471.0\n",
      "done =  False\n",
      "\n",
      "472 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00704059  0.05236512  0.00349369 -0.07735486]\n",
      "reward =  1.0\n",
      "totalReward =  472.0\n",
      "done =  False\n",
      "\n",
      "473 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0080879   0.24743682  0.0019466  -0.36893347]\n",
      "reward =  1.0\n",
      "totalReward =  473.0\n",
      "done =  False\n",
      "\n",
      "474 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01303663  0.05228726 -0.00543207 -0.07563739]\n",
      "reward =  1.0\n",
      "totalReward =  474.0\n",
      "done =  False\n",
      "\n",
      "475 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01408238 -0.1427564  -0.00694482  0.21532676]\n",
      "reward =  1.0\n",
      "totalReward =  475.0\n",
      "done =  False\n",
      "\n",
      "476 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01122725  0.05246415 -0.00263829 -0.07953876]\n",
      "reward =  1.0\n",
      "totalReward =  476.0\n",
      "done =  False\n",
      "\n",
      "477 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01227653 -0.1426199  -0.00422906  0.21231063]\n",
      "reward =  1.0\n",
      "totalReward =  477.0\n",
      "done =  False\n",
      "\n",
      "478 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 9.4241342e-03  5.2562274e-02  1.7152362e-05 -8.1703342e-02]\n",
      "reward =  1.0\n",
      "totalReward =  478.0\n",
      "done =  False\n",
      "\n",
      "479 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01047538 -0.14255993 -0.00161691  0.210985  ]\n",
      "reward =  1.0\n",
      "totalReward =  479.0\n",
      "done =  False\n",
      "\n",
      "480 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00762418  0.05258511  0.00260279 -0.08220754]\n",
      "reward =  1.0\n",
      "totalReward =  480.0\n",
      "done =  False\n",
      "\n",
      "481 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00867588 -0.14257406  0.00095863  0.21129544]\n",
      "reward =  1.0\n",
      "totalReward =  481.0\n",
      "done =  False\n",
      "\n",
      "482 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0058244   0.05253417  0.00518454 -0.08108494]\n",
      "reward =  1.0\n",
      "totalReward =  482.0\n",
      "done =  False\n",
      "\n",
      "483 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00687509 -0.1426617   0.00356284  0.21322921]\n",
      "reward =  1.0\n",
      "totalReward =  483.0\n",
      "done =  False\n",
      "\n",
      "484 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00402185  0.05240912  0.00782743 -0.07832772]\n",
      "reward =  1.0\n",
      "totalReward =  484.0\n",
      "done =  False\n",
      "\n",
      "485 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00507003  0.24741799  0.00626087 -0.3685308 ]\n",
      "reward =  1.0\n",
      "totalReward =  485.0\n",
      "done =  False\n",
      "\n",
      "486 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01001839  0.05220765 -0.00110974 -0.07388035]\n",
      "reward =  1.0\n",
      "totalReward =  486.0\n",
      "done =  False\n",
      "\n",
      "487 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01106255 -0.14289838 -0.00258735  0.21845224]\n",
      "reward =  1.0\n",
      "totalReward =  487.0\n",
      "done =  False\n",
      "\n",
      "488 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00820458  0.05226046  0.0017817  -0.07504572]\n",
      "reward =  1.0\n",
      "totalReward =  488.0\n",
      "done =  False\n",
      "\n",
      "489 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 9.2497887e-03  2.4735682e-01  2.8078147e-04 -3.6716598e-01]\n",
      "reward =  1.0\n",
      "totalReward =  489.0\n",
      "done =  False\n",
      "\n",
      "490 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01419692  0.05223088 -0.00706254 -0.07439453]\n",
      "reward =  1.0\n",
      "totalReward =  490.0\n",
      "done =  False\n",
      "\n",
      "491 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01524154 -0.14278911 -0.00855043  0.21605179]\n",
      "reward =  1.0\n",
      "totalReward =  491.0\n",
      "done =  False\n",
      "\n",
      "492 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.01238576  0.05245403 -0.00422939 -0.07931601]\n",
      "reward =  1.0\n",
      "totalReward =  492.0\n",
      "done =  False\n",
      "\n",
      "493 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01343484 -0.14260703 -0.00581571  0.21202955]\n",
      "reward =  1.0\n",
      "totalReward =  493.0\n",
      "done =  False\n",
      "\n",
      "494 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.0105827   0.05259758 -0.00157512 -0.08248224]\n",
      "reward =  1.0\n",
      "totalReward =  494.0\n",
      "done =  False\n",
      "\n",
      "495 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.01163465 -0.14250176 -0.00322477  0.20970331]\n",
      "reward =  1.0\n",
      "totalReward =  495.0\n",
      "done =  False\n",
      "\n",
      "496 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00878462  0.05266615  0.0009693  -0.08399511]\n",
      "reward =  1.0\n",
      "totalReward =  496.0\n",
      "done =  False\n",
      "\n",
      "497 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00983794 -0.14246967 -0.0007106   0.20899348]\n",
      "reward =  1.0\n",
      "totalReward =  497.0\n",
      "done =  False\n",
      "\n",
      "498 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00698855  0.05266242  0.00346927 -0.08391353]\n",
      "reward =  1.0\n",
      "totalReward =  498.0\n",
      "done =  False\n",
      "\n",
      "499 : --------------------------\n",
      "action =  0\n",
      "observation =  [ 0.00804179 -0.14250909  0.001791    0.20986193]\n",
      "reward =  1.0\n",
      "totalReward =  499.0\n",
      "done =  False\n",
      "\n",
      "500 : --------------------------\n",
      "action =  1\n",
      "observation =  [ 0.00519161  0.05258721  0.00598823 -0.08225548]\n",
      "reward =  1.0\n",
      "totalReward =  500.0\n",
      "done =  True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save best solution for a replay:\n",
    "cartPole = cart_pole.CartPole(RANDOM_SEED)\n",
    "cartPole.saveParams(best)\n",
    "cartPole.replay(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 100 episodes using the best solution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Store/workspace/Computational_Intelligence/cart_pole.py:66: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"getScore\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /mnt/Store/workspace/Computational_Intelligence/cart_pole.py (77)\n",
      "\n",
      "File \"cart_pole.py\", line 77:\n",
      "    def getScore(self, netParams):\n",
      "        <source elided>\n",
      "\n",
      "        mlp = self.initMlp(netParams)\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"getScore\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"cart_pole.py\", line 67:\n",
      "    @jit\n",
      "    def getScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/lizhiyuan/anaconda3/envs/ci/lib/python3.10/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"cart_pole.py\", line 67:\n",
      "    @jit\n",
      "    def getScore(self, netParams):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores =  [500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0]\n",
      "Avg. score =  500.0\n"
     ]
    }
   ],
   "source": [
    "# find average score of 100 episodes using the best solution found:\n",
    "print(\"Running 100 episodes using the best solution...\")\n",
    "scores = []\n",
    "for test in range(100):\n",
    "    scores.append(cart_pole.CartPole().getScore(best))\n",
    "print(\"scores = \", scores)\n",
    "print(\"Avg. score = \", sum(scores) / len(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pso.gbest_y_hist)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fa5b70e74eb62c2393c6b193cb6aa0652f44793bd960bd4296e0878c0311a38"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ci')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
